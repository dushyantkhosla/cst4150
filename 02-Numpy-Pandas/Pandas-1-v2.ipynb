{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "# The Data Science Process\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "A quick look at the OSEMN process for doing data science\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/ds_process_2.png\" alt=\"Fig 3-2 OSEMN Things\" style=\"width: 1000px\">\n",
    "</center>\n",
    "\n",
    "\n",
    "Broadly, it consists of the following steps\n",
    "\n",
    "| Step          | Task                                     |\n",
    "| :------------ | :--------------------------------------- |\n",
    "| 1.  Question  | Clearly define the business problem      |\n",
    "| 2.  Get Data  | Obtain data from internal/external sources, APIs |\n",
    "| 3.  Wrangle   | Clean messy data. Engineer features. Summarize, aggregate data. |\n",
    "| 4.  Explore   | Visualize distributions. Investigate relationships. Build intuition for subsequent steps. |\n",
    "| 5.  Model     | Build and Tune models. Select the best from competing statistical models. |\n",
    "| 6.  Interpret | Assess model performance on out-of-sample data. Understand results. Draw Insights. |\n",
    "| 7.  Deploy    | Productionalize your analysis. Build a data product. |\n",
    "\n",
    "<br>\n",
    "\n",
    "In this section, we will focus on **#2 - Get Data** and **#3 - Wrangle** above. \n",
    "But before we begin, a word of caution. \n",
    "\n",
    "Raw data in the real-world is often *messy* and before we conduct any analysis on the data, we must first make it *tidy*. Cleaning data can be a tedious and repetitive task, and handling this problem inefficiently may lead to great exasperation.\n",
    "\n",
    "It is for these reasons that data preparation has often been labeled by various practitioners as\n",
    "\n",
    ">  the *least sexy, most time & labour intensive* task in data science.\n",
    "\n",
    "<br> \n",
    "\n",
    "<center>\n",
    "<img src=\"./images/ds_time_spent.png\" width=\"900px\">\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "# Tidy Data\n",
    "\n",
    "If you've ever taken a MOOC or undergraduate course in data analysis, chances are that you received a neatly formatted csv file to begin with. In the real world however, that almost never happens.\n",
    "\n",
    "Here are some of the more commonly observed patterns in unclean data.\n",
    "\n",
    "* Column names are missing or gibberish \n",
    "* Data from multiple variables are concatenated into a single column\n",
    "* **Missing data** are encoded in different ways \n",
    "* Features are stored using varying units of measurement\n",
    "* **Outliers** \n",
    "\n",
    "There are **strategies** to deal with each one of these patterns. The following sections will introuce you to the tools and techniques you can use to perform these janitorial duties. Most of these tasks will be performed in Python using the `pandas` library.\n",
    "\n",
    "Once the data is clean it may still require more work before it can be used to create meaningful visualizations or for building machine learning models. This is where we perform advanced *data wrangling* tasks such as \n",
    "\n",
    "* **Reshaping** long-data to wide-data \n",
    "* **Subsetting** data to retain relevant rows and/or columns \n",
    "* **Aggregating** data using the `split-apply-combine` strategy \n",
    "* **Sorting , Merging** to combine data from different sources\n",
    "\n",
    "If you persevere through these steps, you should have a `tidy` dataset that satisfies the criterion laid down by Hadley Wickham, and makes it easy to carry out data analysis. \n",
    "\n",
    "- Observations are in rows\n",
    "- Variables are in columns\n",
    "- Entities of one kind to be contained in a single dataset (ex. customers, transactions)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "# Pandas: Part 1\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Pandas** is a free, open-source data science library aimed at quick and simplified data munging and exploratory analysis in Python. <br><br> Specifically, it provides high-level data structures like the `DataFrame` (similar to the R `data.frame`) and `Series` (one-dimensional structure with an index) which have rich methods for tackling the entire spectrum of data munging tasks. Additionally, `pandas` has specialized methods for manipulating and visualizing numerical variables and time series data. \n",
    "\n",
    "Pandas creator Wes McKinney started building the library in 2008 during his time at an investment management firm. He was motivated by a need to address a distinct set of data analysis requirements that were not fully satisfiedby any one tool at his disposal at the time.\n",
    "\n",
    "<br>\n",
    "\n",
    "> Python had long been great for data munging and preparation, but less so for data analysis and modeling. Pandas helps fill this gap, enabling you to carry out your entire data analysis workflow in Python without having to switch to a more domain specific language.\n",
    "\n",
    "<br>\n",
    "\n",
    "# Pandas, an introduction\n",
    "\n",
    "Pandas is built on top of numPy, and is designed to eliminate the need for writing loops for any filtering or aggregation work. It is implemented in C, so is around 15x faster than base python.\n",
    "\n",
    "Key Features\n",
    "\n",
    "* Easy handling of ***missing data.*** (`dropna, fillna, ffill, isnull, notnull`)\n",
    "\n",
    "* Simple ***mutations*** of tables (add/remove columns)\n",
    "\n",
    "* Easy ***slicing*** of data (fancy indexing and subsetting)\n",
    "\n",
    "* Automatic ***data alignment*** (by index)\n",
    "\n",
    "* Powerful ***split-apply-combine*** (`groupby`)\n",
    "\n",
    "* Intuitive ***merge/join*** (`concat, join`)\n",
    "\n",
    "* Reshaping and ***Pivoting*** (`stack, pivot`)\n",
    "\n",
    "* ***Hierarchical Labeling*** of axes indices\n",
    "\n",
    "* Robust ***I/O tools*** to work with csv, Excel, flat files, ***databases and HDFS***\n",
    "\n",
    "* Integrated ***Time Series*** Functionality\n",
    "\n",
    "* Easy plotting (`plot`)\n",
    "\n",
    "Pandas is built on a solid foundation of NumPy arrays, and is optimized for performance (pandas is about 15x faster), with essential code pieces written in Cython or C. NumPy’s `ndarray` and its broadcasting capabilities are leveraged extensively. \n",
    "\n",
    "The documentation is available [here](http://pandas.pydata.org)\n",
    "\n",
    "---\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "<center>\n",
    "\n",
    "# Getting Data into Pandas\n",
    "\n",
    "</center>\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "We start, as always, by importing modules and frequently used classes from the module. \n",
    "As per convention, we write\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "```\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Reading Flat Files\n",
    "\n",
    "`pandas` has functions such as `read_csv, read_table, read_fwf` and `read_clipboard` for reading tabular data into a `DataFrame` object. These functions take as arguments the following options:\n",
    "\n",
    "<br>\n",
    "\n",
    "*Which columns to consider?*   \n",
    "* Import the header (`header=`) or provide column names (`names=`)\n",
    " \n",
    "*Type inference and conversion*\n",
    "* Processing dates, combining date and time\n",
    "\n",
    "*Which column serves as the index?* (`index_col=`)\n",
    "* For a hierarchical index, pass a list of column names\n",
    "\n",
    "*Which values to interpret as missing data?* (`na_values=`)\n",
    "* If there are multiple sentinels for missing data, pass a dictionary\n",
    "\n",
    "*If the file is too large, read chunks iteratively* (`nrows=` and `chunksize=`)\n",
    "* This option is particularly helpful if you're working with files whose size runs into several gigabytes.\n",
    "\n",
    "Skipping over rows (`skiprows=`)\n",
    "* Sometimes data files have metadata in the first few lines before the actual data. \n",
    "\n",
    "Interpreting decimal numbers (points or commas to mark thousands)\n",
    "* Depending on where you are in the world, floating point numbers are written differently. For ex. The value of pi is written as 3.142 in India and most places, while in Europe you would write it as 3,142\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## CSV files\n",
    "\n",
    "Reading a CSV is as simple as calling the read_csv function. By default, the read_csv function expects the column separator to be a comma, but you can change that using the sep parameter.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "```python\n",
    " pd.read_csv(filepath, sep=, header=, names=, skiprows=, na_values= ... ) \n",
    "```\n",
    "\n",
    "These functions are also able to pull data from a URL. Just use the URL in place of `filepath` \n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Excel Files\n",
    "\n",
    "Pandas allows you to read and write Excel files, so you can easily read from Excel, write your code in Python, and then write back out to Excel - no need for VBA. Reading Excel files requires the xlrd library. \n",
    "\n",
    "You can install it via pip (`pip install xlrd`).\n",
    "\n",
    "```python\n",
    "football = pd.read_excel('path_to_excel_file.xlsx', 'sheet1')\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## SQL Databases\n",
    "\n",
    "`pandas` also has great support for reading or writing data directly from or to a database. The workflow consists of \n",
    "\n",
    "- *setting up a connection* to the database using add-on libraries like `sql-alchemy` and `psycopg2` that help in establishing connections to databases like RDBMS and Redshift. \n",
    "- *and then passing a SQL query over that connection* to the database. The query results, usually in tabular format, are returned to `pandas` as a `DataFrame` object.\n",
    "\n",
    "\n",
    "```python\n",
    "import sqlite3 \n",
    "\n",
    "conn = sqlite3.connect('my-sqlite-database.db')\n",
    "query = \"SELECT * FROM my-sqlite-database LIMIT 10;\"\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Reading from the Clipboard\n",
    "\n",
    "Sometimes we need to quickly import data from an HTML table or an Excel sheet without needing to import the entire page or workbook. We could then just highlight the required data, hit `CTRL + C`, move over to pandas and run `pd.read_clipboard()`. It may be prudent, after the data is imported into your workspace, to back it up using DataFrame methods like `to_csv`\n",
    "\n",
    "```python\n",
    "df = pd.read_clipboard()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Using `bash` commands to peek at the data\n",
    "\n",
    "One handy feature of Jupyter is that you can issue shell commands from any cell by using the `!` \n",
    "\n",
    "This allows us to use shell functions like `head` and `wc` to glance at our data before importing it\n",
    "\n",
    "This way we can\n",
    "\n",
    "- decide which delimiter is appropriate\n",
    "- check if there are extra rows in the file before the table starts\n",
    "- see if there are any special characters and select an appropriate encoding\n",
    "- check if the file is too large and might need to be imported in chunks due to RAM constraints\n",
    "\n",
    "Example\n",
    "\n",
    "```bash\n",
    "wc -l mydata.csv\n",
    "head -n 10 mydata.csv\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Now let's see some of these  in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dush/2025-26_CST4150_PyMLandAI4FinTech/02 Numpy & Pandas\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy-v2.ipynb    Pandas-1-v2.ipynb Pandas-2.ipynb    \u001b[1m\u001b[36mdata\u001b[m\u001b[m\n",
      "Numpy.ipynb       Pandas-1.ipynb    Pandas-3.ipynb    \u001b[1m\u001b[36mimages\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     892 ./data/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# Inspect file without importing it using bash commands\n",
    "\n",
    "# number of rows\n",
    "!wc -l ./data/titanic.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
      "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
      "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
      "3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n",
      "4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\n",
      "5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,373450,8.05,,S\n",
      "6,0,3,\"Moran, Mr. James\",male,,0,0,330877,8.4583,,Q\n",
      "7,0,1,\"McCarthy, Mr. Timothy J\",male,54,0,0,17463,51.8625,E46,S\n",
      "8,0,3,\"Palsson, Master. Gosta Leonard\",male,2,3,1,349909,21.075,,S\n",
      "9,1,3,\"Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\",female,27,0,2,347742,11.1333,,S\n"
     ]
    }
   ],
   "source": [
    "# first 10 rows\n",
    "!head -10 ./data/titanic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's start writing some pandas code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('./data/titanic.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                   Name   Sex   Age  SibSp  \\\n",
       "889          890         1       1  Behr, Mr. Karl Howell  male  26.0      0   \n",
       "890          891         0       3    Dooley, Mr. Patrick  male  32.0      0   \n",
       "\n",
       "     Parch  Ticket   Fare Cabin Embarked  \n",
       "889      0  111369  30.00  C148        C  \n",
       "890      0  370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./data/towed.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_towed\n",
    "  .loc[:, 'make']\n",
    "  .value_counts()\n",
    "  # .head(5)\n",
    "  # .plot\n",
    "  # .barh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import data from sql\n",
    "\n",
    "df_towed = pd.read_sql(sql=\"SELECT * FROM towed;\", \n",
    "                       con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT distinct make, count(*) as num_vehicles from towed group by 1 order by 2 desc limit 10\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>num_vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEV</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORD</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DODG</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PONT</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOYT</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BUIC</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NISS</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOND</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHRY</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OLDS</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   make  num_vehicles\n",
       "0  CHEV           870\n",
       "1  FORD           605\n",
       "2  DODG           386\n",
       "3  PONT           368\n",
       "4  TOYT           292\n",
       "5  BUIC           283\n",
       "6  NISS           273\n",
       "7  HOND           251\n",
       "8  CHRY           195\n",
       "9  OLDS           144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"\"\"\n",
    "SELECT \n",
    "    distinct make, \n",
    "    count(*) as num_vehicles \n",
    "from \n",
    "    towed \n",
    "group by 1 \n",
    "order by 2 desc \n",
    "limit 10\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "# Pandas Data Structures\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Pandas has two **workhorse** **data structures** – *Series* and *DataFrame* - that provide robust and easy-to-implement solutions to many data analysis tasks. These are built on top of NumPy arrays and inherit many of their methods and functions.\n",
    "\n",
    "Operations using these structures include \n",
    "\n",
    "||||||\n",
    "| ---------- | ------------- | ----------- | -------- | --------- |\n",
    "| **CREATE**     | **SUBSET**        | **INSERT**      | **UPDATE**   | **VIEW**      |\n",
    "| **FILTER** | **APPEND**    | **SORT**    | **JOIN** | **MERGE** |\n",
    "| **GROUP**  | **SUMMARIZE** | **RESHAPE** | **MAP**  | **APPLY** |\n",
    "\n",
    "\n",
    "## Series \n",
    "\n",
    "A `Series` is a one-dimensional, homogeneous array-like data structure containing a vector of data (of any valid NumPy type) and an associated array of data labels, called its *index*.\n",
    "\n",
    "### Creating a Series\n",
    "\n",
    "A Series can be created by calling the `pd.Series()` function on a NumPy 1D array or a Python collection like `list, tuple,` or `dictionary`. The index of the Series could be constructed in the same way from one of these objects. If the index isn't explicitly specified, a numeric vector from 0 to length-1 is automatically generated as the index. Additionally, the user may specify the *type* and a *name* while declaring a Series.\n",
    "\n",
    "**Syntax**\n",
    "\n",
    "```python\n",
    "pd.Series(data=, index=, dtype=, name=)\n",
    "```\n",
    "\n",
    "**Examples**\n",
    "\n",
    "```python\n",
    "# Basic Series with no explicit index from an array \n",
    "In []: series_1 = pd.Series(np.random.random(5).round(2))\n",
    "In []: series_1\n",
    "Out[]: \n",
    "0    0.03\n",
    "1    0.94\n",
    "2    0.69\n",
    "3    0.16\n",
    "4    0.61\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, we created a series called *series_1* using an array of 5 elements filled with random numbers. The type was induced from the data to be *float64* and a numeric index was automatically generated.  Note that this series has no *name.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Series with an explicit index, dtype and name specification\n",
    "In []: series_2 = pd.Series(np.random.randint(0, 100, 5),\n",
    "                            index=list('abcde'),\n",
    "                            dtype=float,\n",
    "                            name='S2') \n",
    "In []: series_2\n",
    "Out[]: \n",
    "a    60.0\n",
    "b    13.0\n",
    "c    54.0\n",
    "d    13.0\n",
    "e    65.0\n",
    "Name: S2, dtype: float64\n",
    "```\n",
    "\n",
    "Here, we create a series of random integers, but convert the type to *float* explicitly. The automatic index is replaced by the one we provide. The name *S2* is important as it will become the column name if this `Series` is imported or concatenated into a `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# From a numeric list\n",
    "In []: pd.Series([-55, 4, 79, 101])\n",
    "Out[]: \n",
    "0    -55\n",
    "1      4\n",
    "2     79\n",
    "3    101\n",
    "dtype: int64\n",
    "\n",
    "# From a tuple\n",
    "In []: pd.Series((1, 2, 3, 4))\n",
    "Out[]: \n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "3    4\n",
    "dtype: int64\n",
    "\n",
    "# From a dictionary\n",
    "# Note that when we use a Python dict to create a Series, the keys become the index.\n",
    "In []: pd.Series({'a': 101, 'b': -55, 'c': 79, 'd': 4})\n",
    "Out[]: \n",
    "a    101\n",
    "b    -55\n",
    "c     79\n",
    "d      4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's see this in action:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.86, -0.62,  0.99,  0.69, -0.86,  2.93, -0.24,  0.62, -1.55,\n",
       "        0.22])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_random = np.random.randn(10).round(2)\n",
    "\n",
    "print(type(x_random))\n",
    "x_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind_0    0.86\n",
       "ind_1   -0.62\n",
       "ind_2    0.99\n",
       "ind_3    0.69\n",
       "ind_4   -0.86\n",
       "ind_5    2.93\n",
       "ind_6   -0.24\n",
       "ind_7    0.62\n",
       "ind_8   -1.55\n",
       "ind_9    0.22\n",
       "Name: my_series_1, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\n",
    "    data=x_random, \n",
    "    name='my_series_1',\n",
    "    dtype=float,\n",
    "    index=['ind_' + str(i) for i in range(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_random = pd.Series(x_random)\n",
    "# no index specified, numeric will be automatically generated\n",
    "\n",
    "print(type(s_random))\n",
    "s_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing an index specifically\n",
    "my_series = pd.Series(x_random, index=list('aabbbccdef'))\n",
    "\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': np.float64(0.74),\n",
       " 'b': np.float64(0.88),\n",
       " 'c': np.float64(0.84),\n",
       " 'd': np.float64(0.34),\n",
       " 'e': np.float64(0.75),\n",
       " 'f': np.float64(0.84),\n",
       " 'g': np.float64(0.45),\n",
       " 'h': np.float64(0.94),\n",
       " 'i': np.float64(0.07),\n",
       " 'j': np.float64(0.54)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a list, tuple or dict\n",
    "\n",
    "dict_1 = {v: k for k, v in zip(np.random.random(10).round(2), list('abcdefghij'))}\n",
    "dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.74\n",
       "b    0.88\n",
       "c    0.84\n",
       "d    0.34\n",
       "e    0.75\n",
       "f    0.84\n",
       "g    0.45\n",
       "h    0.94\n",
       "i    0.07\n",
       "j    0.54\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=[1, 2, 3], \n",
    "       index=list('abc'), \n",
    "       name='Series_1', \n",
    "       dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=(1, 2, 3), \n",
    "       index=list('abc'), \n",
    "       name='Series_1', \n",
    "       dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series({'a': 1, 'b': 2, 'c':3}, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_towed.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Series Attributes\n",
    "\n",
    "Just like attributes for primitive Python data structures like `Lists` or `Dictionaries` provide useful metadata about the contents of the data structure, we can use `Series` attributes like `values,  index, shape` to get the underlying array, the index and the length of the series respectively.\n",
    "\n",
    "```python\n",
    "In []: series_2\n",
    "Out[]:\n",
    "a    34.0\n",
    "b    60.0\n",
    "c    21.0\n",
    "d    22.0\n",
    "e     7.0\n",
    "Name: S2, dtype: float64\n",
    "        \n",
    "# Get the underlying NumPy array\n",
    "In []: series_2.values\n",
    "Out[]: array([ 34.,  60.,  21.,  22.,   7.])\n",
    "\n",
    "# Get the index\n",
    "In []: series_2.index\n",
    "Out[]: Index([u'a', u'b', u'c', u'd', u'e'], dtype='object')\n",
    "\n",
    "# Get the size on disk\n",
    "In []: series_2.nbytes\n",
    "Out[]: 40\n",
    "\n",
    "# Get the number of elements\n",
    "In []: series_2.shape\n",
    "Out[]: (5,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=np.arange(5), index=list('uvwxy'))[['w', 'x']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting a Series\n",
    "\n",
    "There are many ways to extract subsets of a Series in Pandas. In addition to allowing NumPy-like subsetting using integer lists and slices, it is possible to subset a Series using \n",
    "\n",
    "* *label-based indexing* by passing index labels associated with the values\n",
    "* *fancy indexing* using methods like `loc, iloc, ix, at, iat`\n",
    "* *boolean indexing* for subsetting with logical arrays\n",
    "\n",
    "Example: Label and integer based indexing on a *Breakfast Menu* \n",
    "\n",
    "```python\n",
    "In [16]: menu = Series({'ham': 1, 'eggs': 3, 'bacon': 2, \n",
    "                        'coffee': 1, 'toast': 0.5, 'jam': 0.2})\n",
    "In [17]: menu\n",
    "Out[17]: \n",
    "bacon     2.0\n",
    "coffee    1.0\n",
    "eggs      3.0\n",
    "ham       1.0\n",
    "jam       0.2\n",
    "toast     0.5\n",
    "dtype: float64\n",
    "\n",
    "# A single label\n",
    "In [18]: menu['bacon']\n",
    "Out[18]: 2.0\n",
    "\n",
    "# A list of labels    \n",
    "In [19]: menu[['eggs', 'bacon']]\n",
    "Out[19]: \n",
    "eggs     3.0\n",
    "bacon    2.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "```python\n",
    "# A slice of labels\n",
    "In [20]: menu['bacon':'eggs']\n",
    "Out[20]: \n",
    "bacon     2.0\n",
    "coffee    1.0\n",
    "eggs      3.0\n",
    "dtype: float64\n",
    "\n",
    "# Another label slice\n",
    "In [21]: menu['ham':]\n",
    "Out[21]: \n",
    "ham      1.0\n",
    "jam      0.2\n",
    "toast    0.5\n",
    "dtype: float64\n",
    "\n",
    "# Positional Slicing\n",
    "In [22]: menu[0:3]\n",
    "Out[22]: \n",
    "bacon     2.0\n",
    "coffee    1.0\n",
    "eggs      3.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### Subsetting with *fancy indexing* methods  \n",
    "\n",
    "  * `.loc()  ` for label based subsetting\n",
    "  * `.iloc()` for integer based subsetting\n",
    "\n",
    "  Note that other methods such as `.ix()` and `.at(), .iat()` exist, but they serve the same purpose. So we will leave it to the reader to explore these functions in the documentation and pick the one they feel most productive in using. \n",
    "\n",
    "```python\n",
    "# Using loc\n",
    "In [30]: menu.loc['coffee']\n",
    "Out[30]: 1.0\n",
    "\n",
    "In [31]: menu.loc['eggs':'jam']\n",
    "Out[31]: \n",
    "eggs    3.0\n",
    "ham     1.0\n",
    "jam     0.2\n",
    "dtype: float64\n",
    "\n",
    "# Using iloc    \n",
    "In [32]: menu.iloc[3]\n",
    "Out[32]: 1.0\n",
    "\n",
    "In [33]: menu.iloc[2:4]\n",
    "Out[33]: \n",
    "eggs    3.0\n",
    "ham     1.0\n",
    "dtype: float64\n",
    "\n",
    "```\n",
    "\n",
    "### Boolean indexing \n",
    "\n",
    "- Works in the same way as it does for subsetting NumPy arrays. \n",
    "\n",
    "- We create a boolean of the same length as the Series, (using the same Series), and then pass the boolean to the squre bracket subsetter. \n",
    "\n",
    "```python\n",
    "# Create a boolean series using a logical comparison\n",
    "In [35]: menu > 1\n",
    "Out[35]: \n",
    "bacon      True\n",
    "coffee    False\n",
    "eggs       True\n",
    "ham       False\n",
    "jam       False\n",
    "toast     False\n",
    "dtype: bool\n",
    "\n",
    "# Subset the series using the boolean to retain values where True\n",
    "In [36]: menu[menu > 1]\n",
    "Out[36]: \n",
    "bacon    2.0\n",
    "eggs     3.0\n",
    "dtype: float64\n",
    "\n",
    "# We can also pass any arbitrary boolean (needs to be of the same length)     \n",
    "In [37]: menu[[True, True, False, False, True, False]]\n",
    "Out[37]: \n",
    "bacon     2.0\n",
    "coffee    1.0\n",
    "jam       0.2\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Practice subsetting with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.30\n",
       "b    1.20\n",
       "c    0.01\n",
       "d   -0.47\n",
       "e   -1.02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_series = pd.Series(data=np.random.randn(5).round(2), index=list('abcde'))\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    1.20\n",
       "c    0.01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_series[1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    0.01\n",
       "d   -0.47\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_series[2:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Label\n",
    "my_series['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.3\n",
       "b    1.2\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Labels\n",
    "my_series[['a', 'b']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    1.20\n",
       "c    0.01\n",
       "d   -0.47\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Slice\n",
    "my_series['b':'d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.30\n",
       "b    1.20\n",
       "c    0.01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positional slicing\n",
    "my_series[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[::-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.loc[['a', 'c', 'e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.iloc[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Detour:: MARKDOWN SHORTCUTS\n",
    "\n",
    "Command mode = press escape or click outside a cell\n",
    "\n",
    "m for markdown\n",
    "y for python/code\n",
    "r for raw\n",
    "\n",
    "a to add a new cell above\n",
    "b to add a new cell below\n",
    "dd to delete a cell\n",
    "\n",
    "to run a cell - SHIFT + ENTER\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "## Series Methods\n",
    "\n",
    "We've just seen a few `Series` methods that allow us to subset data. There's a variety of other methods that are useful across the entire spectrum of data wrangling tasks. The figure below shows an exhaustive list of all methods. We will discuss some of the most important ones of these here, and encourage the readers to peruse the latest pandas documentation to explore other methods.\n",
    "\n",
    "![80% center](./images/Series_methods.png)\n",
    "\n",
    "It is impossible to remember each by heart, so we will rely on our old friend `?` to ask for help\n",
    "\n",
    "`pd.Series.<unknown-method>?`\n",
    "\n",
    "\n",
    "---\n",
    "### Peeking at the data\n",
    "\n",
    "* `head and tail`  are used to view a small sample of a Series or DataFrame object, use the [`head()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html#pandas.DataFrame.head) and [`tail()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html#pandas.DataFrame.tail) methods. The default number of elements to display is five, but you may pass a custom number.\n",
    "\n",
    "```python\n",
    "In [44]: series_8 = Series(np.random.randn(1000).round(2))\n",
    "\n",
    "In [45]: series_8.head()\n",
    "Out[45]: \n",
    "0   -0.23\n",
    "1    0.55\n",
    "2    0.77\n",
    "3    0.18\n",
    "4    0.76\n",
    "dtype: float64\n",
    "\n",
    "In [46]: series_8.tail()\n",
    "Out[46]: \n",
    "995    0.66\n",
    "996   -0.48\n",
    "997    1.13\n",
    "998    1.05\n",
    "999    1.61\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Type Conversion\n",
    "\n",
    "* `astype` explicitly convert dtypes from one to another\n",
    "\n",
    "```python\n",
    "In [51]: series_8.head()\n",
    "Out[51]: \n",
    "0   -0.23\n",
    "1    0.55\n",
    "2    0.77\n",
    "3    0.18\n",
    "4    0.76\n",
    "dtype: float\n",
    "\n",
    "In [52]: series_8.astype(str).head()\n",
    "Out[52]: \n",
    "0    -0.23\n",
    "1     0.55\n",
    "2     0.77\n",
    "3     0.18\n",
    "4     0.76\n",
    "dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Treating Outliers\n",
    "\n",
    "* `clip()` can be used to clip outliers at a threshold value. All values lower than the one supplied to `lower=`, or higher than the one supplied to `upper=` will be replaced by that value. Note how the values in *series_8* below are clipped at the supplied threshold of `0.50`\n",
    "\n",
    "```python\n",
    "In [54]: series_8.head().clip(upper=.50)\n",
    "Out[54]: \n",
    "0   -0.23\n",
    "1    0.50\n",
    "2    0.50\n",
    "3    0.18\n",
    "4    0.50\n",
    "dtype: float64\n",
    "\n",
    "In [55]: series_8.head().clip(lower=.50)\n",
    "Out[55]: \n",
    "0    0.50\n",
    "1    0.55\n",
    "2    0.77\n",
    "3    0.50\n",
    "4    0.76\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "This function is especially useful in **treating outliers** when used in conjunction with `.quantile()` \n",
    "**Note**: In data wrangling, we generally clip values at the 1st-99th Percentile (or the 5th-95th percentile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_1 = pd.Series(data=np.random.randn(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "srs_1.plot.hist(bins=20, figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              Braund, Mr. Owen Harris\n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
       "2                               Heikkinen, Miss. Laina\n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "4                             Allen, Mr. William Henry\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Name'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Male\n",
       "1    Female\n",
       "2    Female\n",
       "3    Female\n",
       "4      Male\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Name'].head(5).map(lambda x: \"Female\" if ('Mrs' in x or 'Miss' in x) else \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(srs_1\n",
    " .clip(upper=srs_1.quantile(0.97))\n",
    " .clip(lower=srs_1.quantile(0.03))\n",
    " .plot\n",
    " .hist(bins=20, figsize=(5, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Replacing Values\n",
    "\n",
    "* `replace` is an effective way to replace source values with target values by suppling a dictionary with the required substitutions. \n",
    "\n",
    "```python\n",
    "In [60]: fruits = Series(['apples', 'oranges', 'peaches', 'mangoes'])\n",
    "In [61]: fruits\n",
    "Out[61]: \n",
    "0     apples\n",
    "1    oranges\n",
    "2    peaches\n",
    "3    mangoes\n",
    "dtype: object\n",
    "\n",
    "In [62]: fruits.replace({'apples':'grapes', 'peaches':'bananas'})\n",
    "Out[62]: \n",
    "0     grapes\n",
    "1    oranges\n",
    "2    bananas\n",
    "3    mangoes\n",
    "dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'AAPL': 'Apple Inc', 'MSFT': 'Microsoft'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Checking if values belong to a list\n",
    "\n",
    "* `isin` produces a boolean by comparing each element of the Series against the provided list. It takes `True` if the element belongs to the list. This boolean may then be used for subsetting the Series. \n",
    "\n",
    "```python\n",
    "In [64]: fruits.isin(['mangoes', 'oranges'])\n",
    "Out[64]: \n",
    "0    False\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "dtype: bool\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booleans can be summed or averaged\n",
    "pd.Series(['apples', 'oranges', 'peaches', 'mangoes']).isin(['peaches', 'mangoes']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Finding uniques and their frequency\n",
    "\n",
    "* `unique, nunique, value_counts` These methods are used to find the array of distinct values in a categorical Series, to count the number of distinct items, and to create a frequency table respectively.\n",
    "\n",
    "```python\n",
    "In [68]: series_9 = Series(list('abcd' * 3))\n",
    "In [69]: series_9\n",
    "Out[69]: \n",
    "0     a\n",
    "1     b\n",
    "2     c\n",
    "3     d\n",
    "4     a\n",
    "5     b\n",
    "6     c\n",
    "7     d\n",
    "8     a\n",
    "9     b\n",
    "10    c\n",
    "11    d\n",
    "dtype: object\n",
    "\n",
    "In [70]: series_9.unique()\n",
    "Out[70]: array(['a', 'b', 'c', 'd'], dtype=object)\n",
    "\n",
    "In [71]: series_9.nunique()\n",
    "Out[71]: 4\n",
    "    \n",
    "In [72]: series_9.value_counts()\n",
    "Out[72]: \n",
    "d    3\n",
    "b    3\n",
    "c    3\n",
    "a    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "All three of these methods prove indespensible while performing visualization and exploratory data analysis (EDA) tasks. \n",
    "For ex. The output produced by `value_counts()` helps us plot bar-charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "S          644\n",
       "C          168\n",
       "Q           77\n",
       "MISSING      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Embarked'].fillna('MISSING').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Dealing with Duplicates\n",
    "\n",
    "* `duplicated` produces a boolean that marks every instance of a value after its first occurrence as True. `drop_duplicates` returns the Series with the duplicates removed. \n",
    "  * If you want to drop duplicated permanently, pass the `inplace=True` argument.\n",
    "\n",
    "```python\n",
    "In [88]: series_9.duplicated()\n",
    "Out[88]: \n",
    "0     False\n",
    "1     False\n",
    "2     False\n",
    "3     False\n",
    "4      True\n",
    "5      True\n",
    "6      True\n",
    "7      True\n",
    "8      True\n",
    "9      True\n",
    "10     True\n",
    "11     True\n",
    "dtype: bool\n",
    "\n",
    "In [89]: series_9.drop_duplicates()\n",
    "Out[89]: \n",
    "0    a\n",
    "1    b\n",
    "2    c\n",
    "3    d\n",
    "dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_9 = pd.Series(list('abcd' * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_9.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Betros, Mr. Tannous                 4.0\n",
       "Carlsson, Mr. Frans Olof            5.0\n",
       "Nysveen, Mr. Johan Hansen           6.0\n",
       "Lemberopolous, Mr. Peter L          6.0\n",
       "Holm, Mr. John Fredrik Alexander    6.0\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_titanic\n",
    "  .set_index('Name')\n",
    "  .query(\"Fare > 0\")\n",
    "  .loc[:, 'Fare']\n",
    "  .nsmallest(5)\n",
    "  .round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Betros, Mr. Tannous'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_titanic\n",
    "  .set_index('Name')\n",
    "  .query(\"Fare > 0\")\n",
    "  .loc[:, 'Fare']\n",
    " .idxmin()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sorting the data\n",
    "\n",
    "* `sort_values`, `sort_index` help in sorting a Series by values or by index in desired order. The `ascending=` argument controls the nature of the sort. \n",
    "\n",
    "  >  *[Note] In order to make the sorting permanent, we need to pass the `inplace=True` argument. The default value `inplace=False` returns a copy of the Series with the changes made, but the original remains intact. Many other methods like `drop_duplicates` also take this paramter.*\n",
    "\n",
    "```python\n",
    "In [82]: series_10.sort_values()\n",
    "Out[82]: \n",
    "y     5\n",
    "c     5\n",
    "a    12\n",
    "x    21\n",
    "z    28\n",
    "b    45\n",
    "dtype: int64    \n",
    "\n",
    "In [83]: series_10.sort_index()\n",
    "Out[83]: \n",
    "a    12\n",
    "b    45\n",
    "c     5\n",
    "x    21\n",
    "y     5\n",
    "z    28\n",
    "dtype: int64\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_1.head(10).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_1.sample(10).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Finding the largest/smallest values\n",
    "\n",
    "* `idxmax, idxmin, nlargest, nsmallest` As their names imply, these methods help in finding the largest, smallest, n-largest and n-smallest respectively. Note that the index label is returned with these values, and this can be especially helpful in EDA.\n",
    "\n",
    "```python\n",
    "In [76]: series_10 = Series(np.random.randint(0, 50, 6), index=list('xyzabc'))\n",
    "\n",
    "In [77]: series_10\n",
    "Out[77]: \n",
    "x    21\n",
    "y     5\n",
    "z    28\n",
    "a    12\n",
    "b    45\n",
    "c     5\n",
    "dtype: int64\n",
    "\n",
    "In [78]: series_10.idxmax()\n",
    "Out[78]: 'b'\n",
    "\n",
    "In [79]: series_10.idxmin()\n",
    "Out[79]: 'y'\n",
    "\n",
    "In [80]: series_10.nlargest(2)\n",
    "Out[80]: \n",
    "b    45\n",
    "z    28\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      32.204208\n",
       "std       49.693429\n",
       "min        0.000000\n",
       "25%        7.910400\n",
       "50%       14.454200\n",
       "75%       31.000000\n",
       "max      512.329200\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Fare'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Mathematical Summaries\n",
    "\n",
    "* `mean, median, std, quantile, describe ` are mathematical methods employed to find the measures of central tendency for a given set of data points. `quantile` finds the requested percentiles, whereas `describe` produces the summary statistics for the data.\n",
    "  These functions come in handy when we're exploring data for patterns.\n",
    "\n",
    "```python\n",
    "# Create a long series with numeric values\n",
    "In [108]: series_11 = Series(np.random.randn(1000))\n",
    "\n",
    "In [109]: series_11.head()\n",
    "Out[109]: \n",
    "0   -0.808280\n",
    "1   -0.361064\n",
    "2    1.098265\n",
    "3   -0.400104\n",
    "4   -0.401763\n",
    "dtype: float64\n",
    "\n",
    "In [110]: series_11.mean()\n",
    "Out[110]: 0.010034515870708844\n",
    "\n",
    "In [111]: series_11.std()\n",
    "Out[111]: 0.9999153362726881\n",
    "\n",
    "In [112]: series_11.median()\n",
    "Out[112]: 0.008293242730166963\n",
    "\n",
    "# Find the 10th, 50th and 80th percentile    \n",
    "In [113]: series_11.quantile([0.10, 0.50, 0.80])\n",
    "Out[113]: \n",
    "0.1   -1.290976\n",
    "0.5    0.008293\n",
    "0.8    0.854793\n",
    "dtype: float64\n",
    "\n",
    "# Get all summary statistics\n",
    "In [114]: series_11.describe()\n",
    "Out[114]: \n",
    "count    1000.000000\n",
    "mean        0.010035\n",
    "std         0.999915\n",
    "min        -3.095835\n",
    "25%        -0.665170\n",
    "50%         0.008293\n",
    "75%         0.693991\n",
    "max         3.762116\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', 'MISSING'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Embarked'].fillna(\"MISSING\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(14.4542)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['Fare'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "* `isnull, notnull ` are complementary methods that work on a Series with missing data to produce a boolean Series that identifies missing or non-missing values respectively. \n",
    "\n",
    ">  Note that both the NumPy `np.nan` and the base Python `None` type are identified as missing values.\n",
    "\n",
    "```python\n",
    "In [93]: series_12 = Series([1.12, 3.14, np.nan, 6.02, 2.73, None])\n",
    "\n",
    "In [94]: series_12\n",
    "Out[94]: \n",
    "0    1.12\n",
    "1    3.14\n",
    "2     NaN\n",
    "3    6.02\n",
    "4    2.73\n",
    "5     NaN\n",
    "dtype: float64\n",
    "\n",
    "# Mark the missing values as True\n",
    "In [95]: series_12.isnull()\n",
    "Out[95]: \n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4    False\n",
    "5     True\n",
    "dtype: bool\n",
    "\n",
    "# Mark the non-missing values as True     \n",
    "In [96]: series_12.notnull()\n",
    "Out[96]: \n",
    "0     True\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "4     True\n",
    "5    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "These functions may be used in conjunction with `sum` and `mean` to find the number or proportion of missing values in each variable of the imported data. Generally, variables with more than 70- 80% missing values are not useful in data analysis.\n",
    "\n",
    "```python\n",
    "# find number of missing values\n",
    "series_12.isnull().sum()\n",
    "\n",
    "# find percentage of missing values\n",
    "series_12.isnull().mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[889 rows x 12 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.dropna(subset='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Missing Values Imputation\n",
    "\n",
    "* `fillna, ffill and bfill, dropna` This set of Series methods allow us to deal with missing data by choosing to either impute them with a particular value, or by copying the last known value over the missing ones (typically used in time-series analysis.) \n",
    "  We may sometimes want to drop the missing data altogether and `dropna` helps us in doing that.\n",
    "\n",
    "> [Note] It is a common practice in data science to replace missing values in a numeric variable by its mean (or median if the data is skewed) and in categorical variables with its mode.\n",
    "\n",
    "```python\n",
    "In [118]: series_12 = Series([1.12, 3.14, np.nan, 6.02, 2.73, None])\n",
    "\n",
    "# Replace missings with 0\n",
    "In [119]: series_12.fillna(0)\n",
    "Out[119]: \n",
    "0    1.12\n",
    "1    3.14\n",
    "2    0.00s\n",
    "3    6.02\n",
    "4    2.73\n",
    "5    0.00\n",
    "dtype: float64\n",
    "\n",
    "# Replace missings with the mean    \n",
    "In [120]: series_12.fillna(series_12.mean())\n",
    "Out[120]: \n",
    "0    1.1200\n",
    "1    3.1400\n",
    "2    3.2525\n",
    "3    6.0200\n",
    "4    2.7300\n",
    "5    3.2525\n",
    "dtype: float64\n",
    "\n",
    "# Replicate the last non-missing value over the missing ones    \n",
    "In [121]: series_12.ffill()\n",
    "Out[121]: \n",
    "0    1.12\n",
    "1    3.14\n",
    "2    3.14\n",
    "3    6.02\n",
    "4    2.73\n",
    "5    2.73\n",
    "dtype: float64\n",
    "\n",
    "# Return a copy of the Series with missing values removed    \n",
    "In [122]: series_12.dropna()\n",
    "Out[122]: \n",
    "0    1.12\n",
    "1    3.14\n",
    "3    6.02\n",
    "4    2.73\n",
    "dtype: float64    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Apply a function to each element\n",
    "\n",
    "*  `map` is perhaps the **most important** of all Series methods. It takes a *general-purpose* or *user-defined* function and applies it to each value in the Series. Combined with base Python's *lambda functions*, it can be an incredibly powerful tool in transforming a given Series.\n",
    "\n",
    "\n",
    "```python\n",
    "# Let's say we have a list of names stored in a Series\n",
    "In [125]: series_13 = Series(['Dave Smith', 'Jane Doe', 'Carl James', 'Jim Hunt'])\n",
    "\n",
    "In [126]: series_13\n",
    "Out[126]: \n",
    "0    Dave Smith\n",
    "1      Jane Doe\n",
    "2    Carl James\n",
    "3      Jim Hunt\n",
    "dtype: object\n",
    "\n",
    "# Find the length of each name    \n",
    "In [126]: series_13.map(lambda x: len(x))\n",
    "Out[126]: \n",
    "0    10\n",
    "1     8\n",
    "2    10\n",
    "3     8\n",
    "dtype: int64\n",
    "\n",
    "# Find the initials    \n",
    "In [127]: series_13.map(lambda x: '.'.join([i[0] for i in x.split(' ')]))\n",
    "Out[127]: \n",
    "0    D.S\n",
    "1    J.D\n",
    "2    C.J\n",
    "3    J.H\n",
    "dtype: object    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_13 = pd.Series(['Dave Smith', 'Jane Doe', 'Carl James', 'Jim Hunt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('dushyant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_13.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['Dave Smith', 'Jane Doe', 'Carl James', 'Jim Hunt']:\n",
    "    print(name.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.split()[0] for x in ['Dave Smith', 'Jane Doe', 'Carl James', 'Jim Hunt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first name\n",
    "series_13.map(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_name(name):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return name.split(' ')[0]\n",
    "\n",
    "series_13.map(get_first_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_13.map(lambda i: get_first_name(name=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_1.map(lambda x: True if x < 0.05 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(data=np.random.randint(low=0, high=100, size=100))\n",
    " .map(lambda x: np.sqrt(x) if x % 2 == 0 else x * x * x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=[1.01, 2.33, 4.33], name='USD').map(lambda x: x * 3.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Visualize the Data\n",
    "\n",
    "* The `plot` method is a gateway to a treasure trove of potential visualizations like histograms, bar charts, scatterplots, boxplots and more. As examples, we will visualize a bar chart for a categorical series and the histogram of a numeric variable.\n",
    "\n",
    "```python\n",
    "# Create a categorical series\n",
    "In [148]: series_14 = Series(list('a' * 3) + list('b' * 5) + list('c' * 9) + list('d' * 2))\n",
    "    \n",
    "In [150]: series_14.value_counts().plot.bar()    \n",
    "```\n",
    "\n",
    "![](./images/series_plot_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "In [151]: series_15 = Series(np.random.randn(1000))\n",
    "\n",
    "In [151]: series_15.head()\n",
    "Out[151]: \n",
    "0    1.796526\n",
    "1    0.323100\n",
    "2   -1.747839\n",
    "3   -0.435137\n",
    "4    0.182139\n",
    "dtype: float64\n",
    "\n",
    "In [152]: series_15.plot.hist()\n",
    "```\n",
    "\n",
    "![](./images/series_plot_1.png)\n",
    "\n",
    "There are extensive customiztions that we can make to the aesthetics of these plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_14 = pd.Series(list('a' * 3) + list('b' * 5) + list('c' * 9) + list('d' * 2))\n",
    "series_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_14.value_counts(normalize=True).plot.barh(color='salmon', title='my first chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Difference between None and NaN\n",
    "\n",
    "- `NaN` is a mathematical entity\n",
    "- `None` is for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(np.nan)\n",
    "# Truthiness value of np.nan is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series Methods do not discriminate between None and NaN\n",
    "pd.Series({'a': None, 'c': 101, 'b': np.nan, 'd': 'red'}).isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.Series(data=[18, None, 5, None, 13], \n",
    "                   index=['DEL', 'BOM', 'BLR', 'DXB', 'BKK'])\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(cities, cities.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(cities, cities.notnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill\n",
    "cities.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.fillna(cities.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list('Dogs are descended from wolves.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe method on char series\n",
    "pd.Series(list('Dogs are descended from wolves.')).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_str_1 = pd.Series(list('Dogs are descended from wolves.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - instead of describe above use value counts and plot a bar chart\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(srs_str_1\n",
    " .value_counts()\n",
    " .plot\n",
    " .bar(figsize=(7, 3))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2 - same as 1 above, but first convert everything to uppercase and replace spaces with underscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_str_1 = pd.Series(list('Dogs are descended from wolves.'))\n",
    "\n",
    "(srs_str_1   \n",
    " .map(str.upper) # each element converted to uppercase\n",
    " .replace({' ': '_'}) \n",
    " .value_counts()\n",
    " .head(7)\n",
    " .plot\n",
    " .bar(color='lightgreen', # change the bar's color\n",
    "      figsize=(5,3),      # change the figure's size\n",
    "      alpha=0.5,          # transparency at 50%\n",
    "      ylim=(0, 10))       # y-axis limit between 0 and 10\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe method on numeric series\n",
    "\n",
    "ser_x = pd.Series(np.random.normal(0, 1, 10000))\n",
    "ser_x.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_x.describe(percentiles=[0.01, 0.05, 0.97, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_x.describe().loc[['min', 'mean', '50%', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: More Series methods using the Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('./data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_x.loc[:, 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_x.loc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts() for frequency tables\n",
    "df_x['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type conversion\n",
    "df_x['PassengerId'].head().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying a function to each element of a series\n",
    "df_x['Fare'].head().map(lambda x: 'AED ' + str(int(x * 3.9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Sex'].head().map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=df_x['Fare'].values, index=df_x['Name']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=df_x['Fare'].values, index=df_x['Name']).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=df_x['Fare'].values, index=df_x['Name']).loc['Ward, Miss. Anna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding where the maximum value occured\n",
    "fares = pd.Series(df_x['Fare'].values, index=df_x['Name'].values)\n",
    "\n",
    "print(f\"{fares.idxmax()} paid the highest fare of {fares.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort a series\n",
    "df_x.loc[:, 'Fare'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(data=df_x['Fare'].values, index=df_x['Name'])\n",
    " .sort_values(ascending=False)\n",
    " .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(data=df_x['Fare'].values, index=df_x['Name'])\n",
    " .sort_values()\n",
    " .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['Name'].loc[df_x['Cabin'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.loc[df_x['Cabin'].isnull(), 'Fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.loc[df_x['Cabin'].notnull(), 'Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Task\n",
    "\n",
    "Generate a Series of 150 ages with a mean of 35 years. Set every fifteenth value to missing. Find the nex mean. Fill the missing data with (a) mean (b) median, and report the new means\n",
    "\n",
    "hint: use `np.random.randn` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./scripts/task_missings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
